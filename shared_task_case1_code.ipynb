{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81f2488c-bd0b-4ff2-b9ec-01df0227acf8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Necessary Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b80b7b12-dead-4f1f-a74e-870eddecc14b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: spacy in ./.local/lib/python3.11/site-packages (3.7.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in ./.local/lib/python3.11/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in ./.local/lib/python3.11/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./.local/lib/python3.11/site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./.local/lib/python3.11/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./.local/lib/python3.11/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in ./.local/lib/python3.11/site-packages (from spacy) (8.2.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in ./.local/lib/python3.11/site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in ./.local/lib/python3.11/site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in ./.local/lib/python3.11/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in ./.local/lib/python3.11/site-packages (from spacy) (0.3.4)\n",
      "Collecting typer<0.10.0,>=0.3.0 (from spacy)\n",
      "  Downloading typer-0.9.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in ./.local/lib/python3.11/site-packages (from spacy) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in ./.local/lib/python3.11/site-packages (from spacy) (4.66.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/modules/Python/3.11.5/lib/python3.11/site-packages (from spacy) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in ./.local/lib/python3.11/site-packages (from spacy) (2.6.4)\n",
      "Requirement already satisfied: jinja2 in /opt/modules/Python/3.11.5/lib/python3.11/site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /opt/modules/Python/3.11.5/lib/python3.11/site-packages (from spacy) (69.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/modules/Python/3.11.5/lib/python3.11/site-packages (from spacy) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in ./.local/lib/python3.11/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/modules/Python/3.11.5/lib/python3.11/site-packages (from spacy) (1.26.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./.local/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in ./.local/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.16.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/modules/Python/3.11.5/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/modules/Python/3.11.5/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/modules/Python/3.11.5/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.local/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/modules/Python/3.11.5/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.11.17)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in ./.local/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in ./.local/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in ./.local/lib/python3.11/site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in ./.local/lib/python3.11/site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/modules/Python/3.11.5/lib/python3.11/site-packages (from jinja2->spacy) (2.1.3)\n",
      "Downloading typer-0.9.4-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: typer\n",
      "  Attempting uninstall: typer\n",
      "    Found existing installation: typer 0.10.0\n",
      "    Uninstalling typer-0.10.0:\n",
      "      Successfully uninstalled typer-0.10.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "en-core-web-sm 3.5.0 requires spacy<3.6.0,>=3.5.0, but you have spacy 3.7.4 which is incompatible.\n",
      "medspacy 1.1.5 requires spacy<3.6,>=3.4.1, but you have spacy 3.7.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed typer-0.9.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf3782bf-906c-4c86-9d1d-637ef87896af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: typer in ./.local/lib/python3.11/site-packages (0.3.2)\n",
      "Collecting typer\n",
      "  Downloading typer-0.10.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: click in ./.local/lib/python3.11/site-packages (7.1.2)\n",
      "Collecting click\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/modules/PythonCentOS7/3.11.5/lib/python3.11/site-packages (from typer) (4.9.0)\n",
      "Downloading typer-0.10.0-py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: click, typer\n",
      "  Attempting uninstall: click\n",
      "    Found existing installation: click 7.1.2\n",
      "    Uninstalling click-7.1.2:\n",
      "      Successfully uninstalled click-7.1.2\n",
      "  Attempting uninstall: typer\n",
      "    Found existing installation: typer 0.3.2\n",
      "    Uninstalling typer-0.3.2:\n",
      "      Successfully uninstalled typer-0.3.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spacy 3.7.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.10.0 which is incompatible.\n",
      "en-core-web-sm 3.5.0 requires spacy<3.6.0,>=3.5.0, but you have spacy 3.7.4 which is incompatible.\n",
      "weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.10.0 which is incompatible.\n",
      "medspacy 1.1.5 requires spacy<3.6,>=3.4.1, but you have spacy 3.7.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed click-8.1.7 typer-0.10.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade typer click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d05c417-f29d-40f1-8c8c-e4533309c0b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openai==0.28 in ./.local/lib/python3.11/site-packages (0.28.0)\n",
      "Requirement already satisfied: requests>=2.20 in /opt/modules/Python/3.11.5/lib/python3.11/site-packages (from openai==0.28) (2.31.0)\n",
      "Requirement already satisfied: tqdm in ./.local/lib/python3.11/site-packages (from openai==0.28) (4.66.1)\n",
      "Requirement already satisfied: aiohttp in ./.local/lib/python3.11/site-packages (from openai==0.28) (3.9.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/modules/Python/3.11.5/lib/python3.11/site-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/modules/Python/3.11.5/lib/python3.11/site-packages (from requests>=2.20->openai==0.28) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.local/lib/python3.11/site-packages (from requests>=2.20->openai==0.28) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/modules/Python/3.11.5/lib/python3.11/site-packages (from requests>=2.20->openai==0.28) (2023.11.17)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/modules/Python/3.11.5/lib/python3.11/site-packages (from aiohttp->openai==0.28) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.local/lib/python3.11/site-packages (from aiohttp->openai==0.28) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.local/lib/python3.11/site-packages (from aiohttp->openai==0.28) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.local/lib/python3.11/site-packages (from aiohttp->openai==0.28) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.local/lib/python3.11/site-packages (from aiohttp->openai==0.28) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai==0.28"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207bbd9e-59ca-43d5-b54f-ba2f9a2d7406",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Necessary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "346f58a4-0dce-40e2-8156-48be46b7cdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "import os\n",
    "import spacy\n",
    "import ast\n",
    "from spacy import displacy\n",
    "import requests\n",
    "import time\n",
    "import re\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "# from wordcloud import WordCloud, STOPWORDS\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)  # None means show all rows\n",
    "pd.set_option('display.max_columns', None)  # None means show all columns\n",
    "pd.set_option('display.width', None)  # None means auto-detect the display width\n",
    "pd.set_option('display.max_colwidth', None)  # None means show full width of columns\n",
    "import openai\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = <your api base>\n",
    "openai.api_version = <api version>\n",
    "openai.api_key = <api key>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ffee001e-b8f0-47b5-b0c4-883d947284d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_ms = pd.read_csv('MEDIQA-CORR-2024-MS-TrainingData.csv')\n",
    "df_val_ms = pd.read_csv('MEDIQA-CORR-2024-MS-ValidationSet-1-Full.csv')\n",
    "df_val_uw = pd.read_csv('MEDIQA-CORR-2024-UW-ValidationSet-1-Full_Feb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "386aa082-d204-4c7c-9c53-2863802f380e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2189, 9)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_ms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c74fc06d-27bb-46ce-8968-4e6ba408ce01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Text ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentences</th>\n",
       "      <th>Error Flag</th>\n",
       "      <th>Error Sentence ID</th>\n",
       "      <th>Error Sentence</th>\n",
       "      <th>Corrected Sentence</th>\n",
       "      <th>Corrected Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2092</th>\n",
       "      <td>2092</td>\n",
       "      <td>ms-train-2092</td>\n",
       "      <td>A 55-year-old patient is brought to the emerge...</td>\n",
       "      <td>0 A 55-year-old patient is brought to the emer...</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>Nitroglycerin was administered to the patient ...</td>\n",
       "      <td>Patient's aspirin dose is increased based on t...</td>\n",
       "      <td>A 55-year-old patient is brought to the emerge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1387</th>\n",
       "      <td>1387</td>\n",
       "      <td>ms-train-1387</td>\n",
       "      <td>A 4-year old boy is brought to the emergency d...</td>\n",
       "      <td>0 A 4-year old boy is brought to the emergency...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2123</th>\n",
       "      <td>2123</td>\n",
       "      <td>ms-train-2123</td>\n",
       "      <td>A previously healthy 8-year-old boy is brought...</td>\n",
       "      <td>0 A previously healthy 8-year-old boy is broug...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0        Text ID  \\\n",
       "2092        2092  ms-train-2092   \n",
       "1387        1387  ms-train-1387   \n",
       "2123        2123  ms-train-2123   \n",
       "\n",
       "                                                   Text  \\\n",
       "2092  A 55-year-old patient is brought to the emerge...   \n",
       "1387  A 4-year old boy is brought to the emergency d...   \n",
       "2123  A previously healthy 8-year-old boy is brought...   \n",
       "\n",
       "                                              Sentences  Error Flag  \\\n",
       "2092  0 A 55-year-old patient is brought to the emer...           1   \n",
       "1387  0 A 4-year old boy is brought to the emergency...           0   \n",
       "2123  0 A previously healthy 8-year-old boy is broug...           0   \n",
       "\n",
       "      Error Sentence ID                                     Error Sentence  \\\n",
       "2092                  7  Nitroglycerin was administered to the patient ...   \n",
       "1387                 -1                                                NaN   \n",
       "2123                 -1                                                NaN   \n",
       "\n",
       "                                     Corrected Sentence  \\\n",
       "2092  Patient's aspirin dose is increased based on t...   \n",
       "1387                                                NaN   \n",
       "2123                                                NaN   \n",
       "\n",
       "                                         Corrected Text  \n",
       "2092  A 55-year-old patient is brought to the emerge...  \n",
       "1387                                                NaN  \n",
       "2123                                                NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_ms.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6501c8-73ef-40ac-bc79-700e14836cde",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Creating a subset from these files (For testing purposes):\n",
    "\n",
    "1. MEDIQA-CORR-2024-MS-TrainingData.csv\n",
    "2. MEDIQA-CORR-2024-MS-ValidationSet-1-Full.csv\n",
    "3. MEDIQA-CORR-2024-UW-ValidationSet-1-Full_Feb.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "3f9bdfcd-dd27-4eea-8723-f826c800fc21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train_ms: (2189, 8)\n",
      "df_val_ms: (574, 8)\n",
      "df_val_uw: (160, 8)\n",
      "Combined dataframe: (2923, 8)\n"
     ]
    }
   ],
   "source": [
    "df_train_ms = pd.read_csv('MEDIQA-CORR-2024-MS-TrainingData.csv',index_col=0)\n",
    "df_val_ms = pd.read_csv('MEDIQA-CORR-2024-MS-ValidationSet-1-Full.csv',index_col=0)\n",
    "df_val_uw = pd.read_csv('MEDIQA-CORR-2024-UW-ValidationSet-1-Full_Feb.csv',index_col=0)\n",
    "min_count = min(df_combined['Error Flag'].value_counts().min(), 50)\n",
    "sampled_df = df_combined.groupby('Error Flag').sample(n=min_count, random_state=42)\n",
    "sampled_df = sampled_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "columns_to_merge = [\"Text ID\", \"GPT_4_error_flag\", \"GPT_4_sentence_id\", \"GPT_4_Error_Sentence\", \"GPT_4_Corrected_Sentence\"]\n",
    "case_1_df = pd.read_csv('case_1.csv')\n",
    "sampled_df = sampled_df.merge(case_1_df[columns_to_merge], on=\"Text ID\", how=\"left\")\n",
    "sampled_df[[\"GPT_4_error_flag\", \"GPT_4_sentence_id\", \"GPT_4_Error_Sentence\", \"GPT_4_Corrected_Sentence\"]] = sampled_df[[\"GPT_4_error_flag\", \"GPT_4_sentence_id\", \"GPT_4_Error_Sentence\", \"GPT_4_Corrected_Sentence\"]].fillna('')\n",
    "\n",
    "sampled_df.to_csv('sampled_ms_uw_df_ea_shared_task.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "ca964de2-88f4-40a7-b340-724a817cf3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train_ms: (2189, 8)\n",
      "df_val_ms: (574, 8)\n",
      "df_val_uw: (160, 8)\n",
      "Combined dataframe: (2923, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(202, 8)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_ms = pd.read_csv('MEDIQA-CORR-2024-MS-TrainingData.csv',index_col=0)\n",
    "df_val_ms = pd.read_csv('MEDIQA-CORR-2024-MS-ValidationSet-1-Full.csv',index_col=0)\n",
    "df_val_uw = pd.read_csv('MEDIQA-CORR-2024-UW-ValidationSet-1-Full_Feb.csv',index_col=0)\n",
    "\n",
    "df_combined = pd.concat([df_train_ms, df_val_ms, df_val_uw], ignore_index=True)\n",
    "print(f\"df_train_ms: {df_train_ms.shape}\\ndf_val_ms: {df_val_ms.shape}\\ndf_val_uw: {df_val_uw.shape}\\nCombined dataframe: {df_combined.shape}\")\n",
    "\n",
    "size_train_ms = df_train_ms.shape[0]\n",
    "size_val_ms = df_val_ms.shape[0]\n",
    "size_val_uw = df_val_uw.shape[0]\n",
    "total_size = size_train_ms + size_val_ms + size_val_uw\n",
    "\n",
    "proportion_train_ms = size_train_ms / total_size\n",
    "proportion_val_ms = size_val_ms / total_size\n",
    "proportion_val_uw = size_val_uw / total_size\n",
    "\n",
    "samples_train_ms = int(round(proportion_train_ms * 300))\n",
    "samples_val_ms = int(round(proportion_val_ms * 300))\n",
    "samples_val_uw = 300 - samples_train_ms - samples_val_ms\n",
    "\n",
    "def sample_balanced(df, n_samples):\n",
    "    df_error = df[df[\"Error Flag\"] == 1]\n",
    "    df_no_error = df[df[\"Error Flag\"] == 0]\n",
    "    n_samples_each = n_samples // 2    \n",
    "    if n_samples % 2 != 0:\n",
    "        n_samples_each += 1\n",
    "    sampled_error = df_error.sample(n=min(n_samples_each, len(df_error)), replace=False)\n",
    "    sampled_no_error = df_no_error.sample(n=min(n_samples_each, len(df_no_error)), replace=False)\n",
    "    return pd.concat([sampled_error, sampled_no_error]).sample(frac=1)  # Randomize order\n",
    "\n",
    "sampled_train_ms = sample_balanced(df_train_ms, samples_train_ms)\n",
    "sampled_val_ms = sample_balanced(df_val_ms, samples_val_ms)\n",
    "sampled_val_uw = sample_balanced(df_val_uw, samples_val_uw)\n",
    "final_df = pd.concat([sampled_train_ms, sampled_val_ms, sampled_val_uw])\n",
    "\n",
    "final_df_balanced = final_df.groupby('Error Flag', group_keys=False).apply(lambda x: x.sample(min(len(x), 150))).sample(frac=1).reset_index(drop=True)\n",
    "final_df_balanced.shape\n",
    "final_df_balanced.to_csv('sampled_ms_uw_df_ea_shared_task_300_texts.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "f17e3963-a376-4f69-9f8b-7463cd7aaac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text ID\n",
       "ms-train    224\n",
       "ms-val       60\n",
       "uw-val       16\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df_balanced['Text ID'].apply(lambda x: '-'.join(x.split('-')[:2])).value_counts()  # Distribution of clinical text taken from the three sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "74e0a4c0-6f56-4c5c-9ba8-f4612a0520f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Error Flag\n",
       "0    150\n",
       "1    150\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df_balanced['Error Flag'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e7147bc-9b78-4299-bdd1-23eb5c9d2f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_ms = pd.read_csv('MEDIQA-CORR-2024-MS-TrainingData.csv',index_col=0)\n",
    "df_val_ms = pd.read_csv('MEDIQA-CORR-2024-MS-ValidationSet-1-Full.csv',index_col=0)\n",
    "df_val_uw = pd.read_csv('MEDIQA-CORR-2024-UW-ValidationSet-1-Full_Feb.csv',index_col=0)\n",
    "total_size = len(df_train_ms) + len(df_val_ms) + len(df_val_uw)\n",
    "ratios = [len(df_train_ms) / total_size, len(df_val_ms) / total_size, len(df_val_uw) / total_size]\n",
    "samples_from_each = [int(200 * ratio) for ratio in ratios]\n",
    "samples_from_each[-1] = 200 - sum(samples_from_each[:-1])\n",
    "sampled_dfs = [df.sample(n) for df, n in zip([df_train_ms, df_val_ms, df_val_uw], samples_from_each)]\n",
    "final_df = pd.concat(sampled_dfs)\n",
    "final_df.shape\n",
    "final_df.to_csv('sampled_ms_uw_df_ea_shared_task_200_texts.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b24eb96-a77d-477a-9c74-a08ac35d953c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text ID\n",
       "ms-train    149\n",
       "ms-val       39\n",
       "uw-val       12\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['Text ID'].apply(lambda x: '-'.join(x.split('-')[:2])).value_counts()  # Distribution of clinical text taken from the three sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb3b5b50-7857-475c-b538-10c5e5c2aeea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Error Flag\n",
       "1    113\n",
       "0     87\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['Error Flag'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23cbefe2-fb36-49f1-9a2c-160187cd04a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_balanced_samples_optimized(df, n_samples=100):\n",
    "    if \"Error Flag\" not in df.columns:\n",
    "        raise ValueError(\"The DataFrame does not have the 'Error Flag' column.\")\n",
    "\n",
    "    # Determine the number of samples per class\n",
    "    n_per_class = n_samples // 2\n",
    "\n",
    "    # Ensure there are enough samples for each class\n",
    "    if df[\"Error Flag\"].value_counts().min() < n_per_class:\n",
    "        raise ValueError(\"Not enough samples in one or both classes to maintain balance.\")\n",
    "\n",
    "    # Efficiently concatenate the random samples from each class\n",
    "    sampled_df = pd.concat([\n",
    "        df[df[\"Error Flag\"] == 0].sample(n=n_per_class, random_state=1),\n",
    "        df[df[\"Error Flag\"] == 1].sample(n=n_per_class, random_state=1)\n",
    "    ])\n",
    "\n",
    "    # Shuffle the resulting DataFrame\n",
    "    sampled_df = sampled_df.sample(frac=1, random_state=2).reset_index(drop=True)\n",
    "\n",
    "    return sampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed953f38-790f-4855-8568-2b91bb0101ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_ms = pd.read_csv('MEDIQA-CORR-2024-MS-TrainingData.csv',index_col=0)\n",
    "df_val_ms = pd.read_csv('MEDIQA-CORR-2024-MS-ValidationSet-1-Full.csv',index_col=0)\n",
    "df_val_uw = pd.read_csv('MEDIQA-CORR-2024-UW-ValidationSet-1-Full_Feb.csv',index_col=0)\n",
    "\n",
    "df_combined = pd.concat([df_train_ms, df_val_ms, df_val_uw], ignore_index=True)\n",
    "extract_balanced_samples_optimized(df_combined, 100).to_csv('sampled_ms_uw_df_ea_shared_task_100_texts.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6807f5c8-20be-474e-8bbb-375fc0daf8cb",
   "metadata": {},
   "source": [
    "# Common Evaluation Metric functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "969a9679-f21c-44a1-8914-b9edc02ee117",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(file_name, gpt_error_flag_name):\n",
    "    df_results = pd.read_csv(file_name,index_col=0)\n",
    "    print(f\"Shape of dataframe:{df_results.shape}\",flush=True)\n",
    "    df_results = df_results.dropna(subset=[gpt_error_flag_name])\n",
    "    print(f\"Shape of dataframe AFTER dropping NANs:{df_results.shape}\",flush=True)\n",
    "    df_results.reset_index(inplace=True)\n",
    "    def convert_value(value):\n",
    "        if value in ['yes', 'Yes']:\n",
    "            return 1\n",
    "        elif value in ['No', 'no']:\n",
    "            return 0\n",
    "        else:\n",
    "            return np.nan\n",
    "    \n",
    "    df_results[gpt_error_flag_name] = df_results[gpt_error_flag_name].apply(convert_value)\n",
    "    print(df_results[gpt_error_flag_name].value_counts(dropna=False))\n",
    "    # df_results = df_results.iloc[:268]    \n",
    "    y_true = df_results['Error Flag']\n",
    "    y_pred = df_results[gpt_error_flag_name]\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    plt.xlabel('Predicted Error Flag (0: no error & 1: Error)')\n",
    "    plt.ylabel('True Error Flag')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    print(f\"True Positives (TP): {tp}\")\n",
    "    print(f\"False Positives (FP): {fp}\")\n",
    "    print(f\"True Negatives (TN): {tn}\")\n",
    "    print(f\"False Negatives (FN): {fn}\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1 Score: {f1:.2f}\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "576b1c68-01c9-425c-bd95-d9e323a74d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe:(574, 12)\n",
      "Shape of dataframe AFTER dropping NANs:(574, 12)\n",
      "gpt_4_1106_preview_error_flag\n",
      "1    466\n",
      "0    108\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives (TP): 284\n",
      "False Positives (FP): 182\n",
      "True Negatives (TN): 73\n",
      "False Negatives (FN): 35\n",
      "Precision: 0.61\n",
      "Recall: 0.89\n",
      "F1 Score: 0.72\n",
      "Accuracy: 0.62\n"
     ]
    }
   ],
   "source": [
    "print_metrics('EA_shared_task_outputs/case1_26_03_2024/case_1_validMS_gpt_4_predictions_26_03_2024.csv','gpt_4_1106_preview_error_flag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c40194ab-9c04-497a-b01b-9e3387b0b946",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe:(466, 8)\n",
      "Shape of dataframe AFTER dropping NANs:(388, 8)\n",
      "Shape of dataframe AFTER dropping NANs:(387, 9)\n",
      "reevaluated_gpt_4_1106_preview_error_flag\n",
      "0.0    244\n",
      "1.0    143\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives (TP): 115\n",
      "False Positives (FP): 28\n",
      "True Negatives (TN): 150\n",
      "False Negatives (FN): 94\n",
      "Precision: 0.80\n",
      "Recall: 0.55\n",
      "F1 Score: 0.65\n",
      "Accuracy: 0.68\n"
     ]
    }
   ],
   "source": [
    "df_results = pd.read_csv('EA_shared_task_outputs/case1_26_03_2024/tempo.csv',index_col=0)\n",
    "\n",
    "print(f\"Shape of dataframe:{df_results.shape}\",flush=True)\n",
    "df_results = df_results.dropna(subset=['reevaluated_gpt_4_1106_preview_error_flag'])\n",
    "print(f\"Shape of dataframe AFTER dropping NANs:{df_results.shape}\",flush=True)\n",
    "df_results.reset_index(inplace=True)\n",
    "def convert_value(value):\n",
    "    if value in ['yes', 'Yes']:\n",
    "        return 1\n",
    "    elif value in ['No', 'no']:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "df_results['reevaluated_gpt_4_1106_preview_error_flag'] = df_results['reevaluated_gpt_4_1106_preview_error_flag'].apply(convert_value)\n",
    "df_results = df_results.dropna(subset=['reevaluated_gpt_4_1106_preview_error_flag'])\n",
    "print(f\"Shape of dataframe AFTER dropping NANs:{df_results.shape}\",flush=True)\n",
    "print(df_results['reevaluated_gpt_4_1106_preview_error_flag'].value_counts(dropna=False))\n",
    "# df_results = df_results.iloc[:271]    \n",
    "y_true = df_results['Error Flag']\n",
    "y_pred = df_results['reevaluated_gpt_4_1106_preview_error_flag']\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(4, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted Error Flag (0: no error & 1: Error)')\n",
    "plt.ylabel('True Error Flag')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"True Positives (TP): {tp}\")\n",
    "print(f\"False Positives (FP): {fp}\")\n",
    "print(f\"True Negatives (TN): {tn}\")\n",
    "print(f\"False Negatives (FN): {fn}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7044456a-46a3-4623-b7bf-9d4fbe16c1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR FLAG:  gpt_4_1106_preview_error_flag\n",
      "1    466\n",
      "0    108\n",
      "Name: count, dtype: int64\n",
      "df.shape:  (574, 13)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(108, 14)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Read the pipeline1's output csv file\n",
    "df = pd.read_csv('EA_shared_task_outputs/case1_26_03_2024/case_1_validMS_gpt_4_predictions_26_03_2024.csv',index_col=0)\n",
    "df = df.dropna(subset=['gpt_4_1106_preview_error_flag'])\n",
    "df['gpt_4_1106_preview_sentence_id'] = df['gpt_4_1106_preview_sentence_id'].astype(int)\n",
    "df['gpt_4_1106_preview_error_flag'] = df['gpt_4_1106_preview_error_flag'].apply(convert_value)\n",
    "print(\"ERROR FLAG: \",df['gpt_4_1106_preview_error_flag'].value_counts(dropna=False))\n",
    "df.reset_index(inplace=True)\n",
    "print(\"df.shape: \",df.shape)\n",
    "\n",
    "## Extract only the positive predictions by gpt-4 api\n",
    "df_0_preds = df[df['gpt_4_1106_preview_error_flag'] ==0]\n",
    "df_0_preds.reset_index(inplace=True)\n",
    "df_0_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0aec39ea-203b-412e-ac13-dba6b63638d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'Unnamed: 0', 'Text ID', 'Text', 'Sentences', 'Error Flag',\n",
       "       'Error Sentence ID', 'Error Sentence', 'Corrected Sentence',\n",
       "       'Corrected Text', 'gpt_4_1106_preview_error_flag',\n",
       "       'gpt_4_1106_preview_sentence_id', 'gpt_4_1106_preview_Error_Sentence',\n",
       "       'gpt_4_1106_preview_Corrected_Sentence'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_0_preds.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf29acc-1e95-41f2-99d7-f732e3bcb7bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9f37c80a-e43f-407b-a7a4-b99a8f22462f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 20)\n",
      "(178, 20)\n",
      "Evaluation Metrics for Model 1:\n",
      "Accuracy: 0.6461\n",
      "Precision: 0.6461\n",
      "Recall: 1.0000\n",
      "F1: 0.7850\n",
      "ROC AUC: N/A (not binary)\n",
      "\n",
      "Evaluation Metrics for Model 2:\n",
      "Accuracy: 0.7247\n",
      "Precision: 0.8173\n",
      "Recall: 0.7391\n",
      "F1: 0.7763\n",
      "ROC AUC: 0.7188\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "df = pd.read_csv('EA_shared_task_outputs/case2_prompt_with_RAG/case2_with_RAG_validMS_gpt_4_predictions_temp_27_03.csv',index_col=0)\n",
    "df = df.iloc[:178]\n",
    "df = df.dropna(subset=['gpt_4_1106_preview_error_flag'])\n",
    "df = df.dropna(subset=['reevaluated_gpt_4_1106_preview_error_flag'])\n",
    "df = df.dropna(subset=['Error Flag'])\n",
    "\n",
    "\n",
    "df.reset_index(inplace=True)\n",
    "print(df.shape)\n",
    "def convert_value(value):\n",
    "        if value in ['yes', 'Yes']:\n",
    "            return 1\n",
    "        elif value in ['No', 'no']:\n",
    "            return 0\n",
    "        else:\n",
    "            return np.nan\n",
    "    \n",
    "df['reevaluated_gpt_4_1106_preview_error_flag'] = df['reevaluated_gpt_4_1106_preview_error_flag'].apply(convert_value)\n",
    "df = df.dropna(subset=['gpt_4_1106_preview_error_flag', 'reevaluated_gpt_4_1106_preview_error_flag'])\n",
    "print(df.shape)\n",
    "\n",
    "def evaluate_metrics(y_true, y_pred, metric_names=[\"Accuracy\", \"Precision\", \"Recall\", \"F1\", \"ROC AUC\"]):\n",
    "    metrics = {}\n",
    "    if \"Accuracy\" in metric_names:\n",
    "        metrics[\"Accuracy\"] = accuracy_score(y_true, y_pred)\n",
    "    if \"Precision\" in metric_names:\n",
    "        metrics[\"Precision\"] = precision_score(y_true, y_pred)\n",
    "    if \"Recall\" in metric_names:\n",
    "        metrics[\"Recall\"] = recall_score(y_true, y_pred)\n",
    "    if \"F1\" in metric_names:\n",
    "        metrics[\"F1\"] = f1_score(y_true, y_pred)\n",
    "    if \"ROC AUC\" in metric_names:\n",
    "        if y_true.nunique() == 2 and y_pred.nunique() == 2:\n",
    "            metrics[\"ROC AUC\"] = roc_auc_score(y_true, y_pred)\n",
    "        else:\n",
    "            metrics[\"ROC AUC\"] = \"N/A (not binary)\"\n",
    "    return metrics\n",
    "\n",
    "gold_standard = \"Error Flag\"\n",
    "model_1_predictions = \"gpt_4_1106_preview_error_flag\"\n",
    "model_2_predictions = \"reevaluated_gpt_4_1106_preview_error_flag\"\n",
    "\n",
    "metrics_model_1 = evaluate_metrics(df[gold_standard], df[model_1_predictions])\n",
    "metrics_model_2 = evaluate_metrics(df[gold_standard], df[model_2_predictions])\n",
    "\n",
    "print(\"Evaluation Metrics for Model 1:\")\n",
    "for metric, value in metrics_model_1.items():\n",
    "    if isinstance(value, str):\n",
    "        print(f\"{metric}: {value}\")\n",
    "    else:\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "print(\"\\nEvaluation Metrics for Model 2:\")\n",
    "for metric, value in metrics_model_2.items():\n",
    "    if isinstance(value, str):\n",
    "        print(f\"{metric}: {value}\")\n",
    "    else:\n",
    "        print(f\"{metric}: {value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e44fc67-cf8a-4796-bdb5-6a2543b02511",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Understanding the input Training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "e00da422-1b37-4ded-bba6-2a424839c239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2189 entries, 0 to 2188\n",
      "Data columns (total 9 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   Unnamed: 0          2189 non-null   int64 \n",
      " 1   Text ID             2189 non-null   object\n",
      " 2   Text                2189 non-null   object\n",
      " 3   Sentences           2189 non-null   object\n",
      " 4   Error Flag          2189 non-null   int64 \n",
      " 5   Error Sentence ID   2189 non-null   int64 \n",
      " 6   Error Sentence      1219 non-null   object\n",
      " 7   Corrected Sentence  1219 non-null   object\n",
      " 8   Corrected Text      1219 non-null   object\n",
      "dtypes: int64(3), object(6)\n",
      "memory usage: 154.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train_ms.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "5f0fc52e-7e9d-4474-a75a-0cc3e012f07f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Error Flag\n",
       "1    1219\n",
       "0     970\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_ms['Error Flag'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "c49c5729-271d-4ad4-ad5c-9b563d159d6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    After reviewing imaging, the causal pathogen was determined to be Haemophilus influenzae.\n",
       "1                                                                                          NaN\n",
       "2                                                 Suspected of infection with Giardia lamblia.\n",
       "3                                                                                          NaN\n",
       "4                                               Causal organism is Staphylococcus epidermidis.\n",
       "5                                                                                          NaN\n",
       "6                                                  Patient is diagnosed with an EBV infection.\n",
       "7                                                                                          NaN\n",
       "8                                   Bartonella henselae was determined as the causal organism.\n",
       "9                                                        Culture confirms Nocardia asteroides.\n",
       "Name: Error Sentence, dtype: object"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_ms['Error Sentence'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86ea3a9-c7a1-4f42-ad7a-18ca4294f57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_text = ' '.join(df_train_ms['Error Sentence'].dropna().str.lower())\n",
    "corrected_text = ' '.join(df_train_ms['Corrected Sentence'].dropna().str.lower())\n",
    "\n",
    "wordcloud_error = WordCloud(stopwords=STOPWORDS, background_color='white').generate(error_text)\n",
    "wordcloud_corrected = WordCloud(stopwords=STOPWORDS, background_color='white').generate(corrected_text)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(wordcloud_error, interpolation='bilinear')\n",
    "plt.title('Error Sentences')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(wordcloud_corrected, interpolation='bilinear')\n",
    "plt.title('Corrected Sentences')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1403fca6-2bc0-4e84-860e-efe980b1fa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "df_train_ms['Text'].apply(len).plot(kind='hist', bins=20, alpha=0.7)\n",
    "plt.title('Frequency of Text Lengths')\n",
    "plt.xlabel('Text Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09279de7-e56c-44da-93fd-dbbbf4807984",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# CASE 1: 7 examples given in Prompt with every feature \n",
    "## (Text, Sentences, Error flag, Error sentence id, error sentence, corrected sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7d973d-3025-4bc1-967a-99933a5e2ac4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######################################################################\n",
      "Currently accessing df_val_ms id:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3357267/21538612.py:195: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'yes' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_val_ms.at[i, 'gpt_4_1106_preview_error_flag'] = message_content_json['Error']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######################################################################\n",
      "Currently accessing df_val_ms id:1\n",
      "#######################################################################\n",
      "Currently accessing df_val_ms id:2\n",
      "#######################################################################\n",
      "Currently accessing df_val_ms id:3\n",
      "#######################################################################\n",
      "Currently accessing df_val_ms id:4\n",
      "#######################################################################\n",
      "Currently accessing df_val_ms id:5\n",
      "#######################################################################\n",
      "Currently accessing df_val_ms id:6\n",
      "#######################################################################\n",
      "Currently accessing df_val_ms id:7\n",
      "#######################################################################\n",
      "Currently accessing df_val_ms id:8\n",
      "#######################################################################\n",
      "Currently accessing df_val_ms id:9\n",
      "#######################################################################\n",
      "Currently accessing df_val_ms id:10\n",
      "#######################################################################\n",
      "Currently accessing df_val_ms id:11\n",
      "#######################################################################\n",
      "Currently accessing df_val_ms id:12\n",
      "#######################################################################\n",
      "Currently accessing df_val_ms id:13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3357267/21538612.py:196: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '-1' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_val_ms.at[i, 'gpt_4_1106_preview_sentence_id'] = message_content_json['Error Sentence ID']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######################################################################\n",
      "Currently accessing df_val_ms id:14\n",
      "#######################################################################\n",
      "Currently accessing df_val_ms id:15\n",
      "#######################################################################\n",
      "Currently accessing df_val_ms id:16\n",
      "#######################################################################\n",
      "Currently accessing df_val_ms id:17\n",
      "#######################################################################\n",
      "Currently accessing df_val_ms id:18\n",
      "#######################################################################\n",
      "Currently accessing df_val_ms id:19\n",
      "#######################################################################\n",
      "Currently accessing df_val_ms id:20\n",
      "#######################################################################\n",
      "Currently accessing df_val_ms id:21\n",
      "#######################################################################\n",
      "Currently accessing df_val_ms id:22\n",
      "#######################################################################\n",
      "Currently accessing df_val_ms id:23\n",
      "#######################################################################\n"
     ]
    }
   ],
   "source": [
    "# CASE When \"or text span\" is removed and \"gpt-4-turbo-preview\" is used\n",
    "df_val_ms = pd.read_csv('MEDIQA-CORR-2024-MS-ValidationSet-1-Full.csv')\n",
    "df_val_ms['gpt_4_1106_preview_error_flag'] = 0\n",
    "df_val_ms['gpt_4_1106_preview_sentence_id'] = 0\n",
    "df_val_ms['gpt_4_1106_preview_Error_Sentence'] = ''\n",
    "df_val_ms['gpt_4_1106_preview_Corrected_Sentence'] = ''\n",
    "\n",
    "max_retries = 3\n",
    "default_wait_time = 6  # Default wait time in seconds\n",
    "\n",
    "# for i in range(len(df_val_ms)):\n",
    "for i, row in df_val_ms.iterrows():\n",
    "    print(\"#######################################################################\")\n",
    "    time.sleep(30)\n",
    "    if i % 5 == 0:\n",
    "        # print(\"Waiting for 10 seconds...\",flush=True)\n",
    "        time.sleep(10)\n",
    "        \n",
    "    retry_count = 0\n",
    "    while retry_count < max_retries:\n",
    "        try:\n",
    "            print(f\"Currently accessing df_val_ms id:{i}\", flush=True)\n",
    "            text = row['Text']\n",
    "            clinical_sentences = row['Sentences']\n",
    "            # print(\"Data read!!\")\n",
    "            message_text = [{\"role\":\"system\",\"content\":\n",
    "                  f\"\"\"You are an AI trained in medical knowledge. Below are examples of clinical texts (delimited by triple quotes) and clinical texts divided into sentences (delimited by triple quotes) followed by an analysis of whether there is a diagnostic error and, if so, the sentence ID and the text span containing the error. The examples also show the corrected sentence that should have been the correct diagnosis.\n",
    "                  Example 1:\n",
    "                  Clinical Text: ```A 17-year-old boy comes to the physician because of body aches and sore throat for 1 week. He has no history of serious illness and takes no medications. He lives with his parents; they recently adopted a cat from an animal shelter. He is sexually active with one female partner, and they use condoms consistently. His temperature is 38.7 C (101.7 F), pulse is 99/min, and blood pressure is 110/72 mm Hg. Examination shows bilateral posterior cervical lymphadenopathy. The pharynx is red and swollen. Laboratory studies show:\n",
    "                  Hemoglobin 15 g/dL\n",
    "                  Leukocyte count 11,500/mm3\n",
    "                  Segmented neutrophils 48%\n",
    "                  Band forms 2%\n",
    "                  Basophils 0.5%\n",
    "                  Eosinophils 1%\n",
    "                  Lymphocytes 45%\n",
    "                  Monocytes 3.5%\n",
    "                  When the patient's serum is added to a sample of horse erythrocytes, the cells aggregate together. The causal pathogen is cytomegalovirus.```\n",
    "                  Clinical Text Sentences: ```0 A 17-year-old boy comes to the physician because of body aches and sore throat for 1 week.\n",
    "                  1 He has no history of serious illness and takes no medications.\n",
    "                  2 He lives with his parents; they recently adopted a cat from an animal shelter.\n",
    "                  3 He is sexually active with one female partner, and they use condoms consistently.\n",
    "                  4 His temperature is 38.7 C (101.7 F), pulse is 99/min, and\n",
    "                  5 blood pressure is 110/72 mm\n",
    "                  6 Hg.\n",
    "                  7 Examination shows bilateral posterior cervical lymphadenopathy.\n",
    "                  8 The pharynx is red and swollen.\n",
    "                  9 Laboratory studies show:\n",
    "                  10 Hemoglobin 15\n",
    "                  11 g/dL\n",
    "                  12 Leukocyte count 11,500/mm3 Segmented neutrophils 48%\n",
    "                  13 Band forms 2%\n",
    "                  14 Basophils 0.5%\n",
    "                  15 Eosinophils 1%\n",
    "                  16 Lymphocytes 45%\n",
    "                  17 Monocytes 3.5%\n",
    "                  18 When the patient's serum is added to a sample of horse erythrocytes, the cells aggregate together.\n",
    "                  19 The causal pathogen is cytomegalovirus.```\n",
    "                  Error: yes\n",
    "                  Error Sentence ID: 19\n",
    "                  Error Sentence Span: The causal pathogen is cytomegalovirus.\n",
    "                  Corrected Sentence: The causal pathogen is Epstein-Barr virus.\n",
    "                \n",
    "                  Example 2:\n",
    "                  Clinical Text: ```A previously healthy 18-year-old woman comes to the emergency department because of diarrhea and abdominal cramps since the previous evening. She has had around 3Ã¢â‚¬â€œ4 episodes of watery stools. She feels nauseous and has vomited twice. She recollects eating out 2 days ago. She has been on a vegan diet for 6 months. She takes no medications and has not traveled anywhere recently. Her temperature is 36.8 (98.2 F), pulse is 73/min, and blood pressure is 110/70 mm Hg. Examination shows dry mucous membranes. Abdominal examination is unremarkable. Norovirus was determined to be the casual organism.```\n",
    "                  Clinical Text Sentences: ```0 A previously healthy 18-year-old woman comes to the emergency department because of diarrhea and abdominal cramps since the previous evening.\n",
    "                  1 She has had around 3Ã¢â‚¬â€œ4 episodes of watery stools.\n",
    "                  2 She feels nauseous and has vomited twice.\n",
    "                  3 She recollects eating out 2 days ago.\n",
    "                  4 She has been on a vegan diet for 6 months.\n",
    "                  5 She takes no medications and has not traveled anywhere recently.\n",
    "                  6 Her temperature is 36.8 (98.2 F), pulse is 73/min, and\n",
    "                  7 blood pressure is 110/70 mm\n",
    "                  8 Hg.\n",
    "                  9 Examination shows dry mucous membranes.\n",
    "                  10 Abdominal examination is unremarkable.\n",
    "                  11 Norovirus was determined to be the casual organism.```\n",
    "                  Error: No\n",
    "                  Error Sentence ID: -1\n",
    "                  Error Sentence Span: -1\n",
    "                  Corrected Sentence: -1\n",
    "                \n",
    "                  Example 3:\n",
    "                  Clinical Text: ```A 5-year-old boy is brought to the emergency department by his grandmother because of difficulty breathing. Over the past two hours, the grandmother has noticed his voice getting progressively hoarser and occasionally muffled, with persistent drooling. He has not had a cough. The child recently immigrated from Africa, and the grandmother is unsure if his immunizations are up-to-date. He appears uncomfortable and is sitting up and leaning forward with his chin hyperextended. His temperature is 39.5 C (103.1 F), pulse is 110/min, and blood pressure is 90/70 mm Hg. Pulse oximetry on room air shows an oxygen saturation of 95%. Pulmonary examination shows inspiratory stridor and scattered rhonchi throughout both lung fields, along with poor air movement. Pharyngoscopy is ordered. ```\n",
    "                  Clinical Text Sentences: ```0 A 5-year-old boy is brought to the emergency department by his grandmother because of difficulty breathing.\n",
    "                  1 Over the past two hours, the grandmother has noticed his voice getting progressively hoarser and occasionally muffled, with persistent drooling.\n",
    "                  2 He has not had a cough.\n",
    "                  3 The child recently immigrated from Africa, and the grandmother is unsure if his immunizations are up-to-date.\n",
    "                  4 He appears uncomfortable and is sitting up and leaning forward with his chin hyperextended.\n",
    "                  5 His temperature is 39.5 C (103.1 F), pulse is 110/min, and blood pressure is 90/70 mm\n",
    "                  6 Hg.\n",
    "                  7 Pulse oximetry on room air shows an oxygen saturation of 95%.\n",
    "                  8 Pulmonary examination shows inspiratory stridor and scattered rhonchi throughout both lung fields, along with poor air movement.\n",
    "                  9 Pharyngoscopy is ordered.```\n",
    "                  Error: yes\n",
    "                  Error Sentence ID: 9\n",
    "                  Error Sentence Span: Pharyngoscopy is ordered.\n",
    "                  Corrected Sentence: Nasotracheal intubation is performed.\n",
    "                \n",
    "                  Example 4:\n",
    "                  Clinical Text:```A 28-year-old man is brought to the emergency department after being struck by a car an hour ago as he was crossing the street. He did not lose consciousness. He is complaining of pain in his right arm, forehead, and pelvis. He also has the urge to urinate, but has been unable to do so since the accident. He takes no medications. His temperature is 37.1 C (98.9 F), pulse is 72/min, respirations are 18/min, and blood pressure is 118/82 mm Hg. There are abrasions over his scalp and face and a 1x3 cm area of ecchymosis above his right eye. Abdominal examination shows suprapubic tenderness. There is a scant amount of blood at the urethral meatus. There is no cervical spinal tenderness. Musculoskeletal examination shows tenderness and ecchymosis over his right distal forearm. An x-ray of the pelvis shows a fracture of the pelvic ramus. Retrograde urethrogram was then performed. A CT scan of the head and neck show no abnormalities.```\n",
    "                  Clinical Text Sentences: ```0 A 28-year-old man is brought to the emergency department after being struck by a car an hour ago as he was crossing the street.\n",
    "                  1 He did not lose consciousness.\n",
    "                  2 He is complaining of pain in his right arm, forehead, and pelvis.\n",
    "                  3 He also has the urge to urinate, but has been unable to do so since the accident.\n",
    "                  4 He takes no medications.\n",
    "                  5 His temperature is 37.1 C (98.9 F), pulse is 72/min, respirations are 18/min, and\n",
    "                  6 blood pressure is 118/82 mm\n",
    "                  7 Hg.\n",
    "                  8 There are abrasions over his scalp and face and a 1x3 cm area of ecchymosis above his right eye.\n",
    "                  9 Abdominal examination shows suprapubic tenderness.\n",
    "                  10 There is a scant amount of blood at the urethral meatus.\n",
    "                  11 There is no cervical spinal tenderness.\n",
    "                  12 Musculoskeletal examination shows tenderness and ecchymosis over his right distal forearm.\n",
    "                  13 An x-ray of the pelvis shows a fracture of the pelvic ramus.\n",
    "                  14 Retrograde urethrogram was then performed.\n",
    "                  15 A CT scan of the head and neck show no abnormalities.```\n",
    "                  Error: No\n",
    "                  Error Sentence ID: -1\n",
    "                  Error Sentence Span: -1\n",
    "                  Corrected Sentence: -1\n",
    "                \n",
    "                  Example 5:\n",
    "                  Clinical Text: ```A 28-year-old man is brought to the emergency department after being struck by a car an hour ago as he was crossing the street. He did not lose consciousness. He is complaining of pain in his right arm, forehead, and pelvis. He also has the urge to urinate, but has been unable to do so since the accident. He takes no medications. His temperature is 37.1 C (98.9 F), pulse is 72/min, respirations are 18/min, and blood pressure is 118/82 mm Hg. There are abrasions over his scalp and face and a 1x3 cm area of ecchymosis above his right eye. Abdominal examination shows suprapubic tenderness. There is a scant amount of blood at the urethral meatus. There is no cervical spinal tenderness. Musculoskeletal examination shows tenderness and ecchymosis over his right distal forearm. An x-ray of the pelvis shows a fracture of the pelvic ramus. A CT scan of the head and neck show no abnormalities. IV pyelogram was then performed.```\n",
    "                  Clinical Text Sentences: ```0 A 28-year-old man is brought to the emergency department after being struck by a car an hour ago as he was crossing the street.\n",
    "                  1 He did not lose consciousness.\n",
    "                  2 He is complaining of pain in his right arm, forehead, and pelvis.\n",
    "                  3 He also has the urge to urinate, but has been unable to do so since the accident.\n",
    "                  4 He takes no medications.\n",
    "                  5 His temperature is 37.1 C (98.9 F), pulse is 72/min, respirations are 18/min, and\n",
    "                  6 blood pressure is 118/82 mm\n",
    "                  7 Hg.\n",
    "                  8 There are abrasions over his scalp and face and a 1x3 cm area of ecchymosis above his right eye.\n",
    "                  9 Abdominal examination shows suprapubic tenderness.\n",
    "                  10 There is a scant amount of blood at the urethral meatus.\n",
    "                  11 There is no cervical spinal tenderness.\n",
    "                  12 Musculoskeletal examination shows tenderness and ecchymosis over his right distal forearm.\n",
    "                  13 An x-ray of the pelvis shows a fracture of the pelvic ramus.\n",
    "                  14 A CT scan of the head and neck show no abnormalities.\n",
    "                  15 IV pyelogram was then performed.```\n",
    "                  Error: yes\n",
    "                  Error Sentence ID: 15\n",
    "                  Error Sentence Span: IV pyelogram was then performed.\n",
    "                  Corrected Sentence: Retrograde urethrogram was then performed.\n",
    "                \n",
    "                  Example 6:\n",
    "                  Clinical Text: ```A previously healthy 25-year-old man comes to the physician because of a 4-day history of fever, joint and body pain, diffuse headache, and pain behind the eyes. This morning he noticed that his gums bled when he brushed his teeth. He returned from a backpacking trip to the Philippines 4 days ago. His temperature is 39.4 C (103.0 F). Physical examination shows a diffuse maculopapular rash. His leukocyte count is 3,200/mm3 and platelet count is 89,000/mm3. Further evaluation shows increased serum levels of a flavivirus. The patient is infected by the chikungunya virus.```\n",
    "                  Clinical Text Sentences: ```0 A previously healthy 25-year-old man comes to the physician because of a 4-day history of fever, joint and body pain, diffuse headache, and pain behind the eyes.\n",
    "                  1 This morning he noticed that his gums bled when he brushed his teeth.\n",
    "                  2 He returned from a backpacking trip to the Philippines 4 days ago.\n",
    "                  3 His temperature is 39.4 C (103.0 F).\n",
    "                  4 Physical examination shows a diffuse maculopapular rash.\n",
    "                  5 His leukocyte count is\n",
    "                  6 3,200/mm3 and platelet count is 89,000/mm3.\n",
    "                  7 Further evaluation shows increased serum levels of a flavivirus.\n",
    "                  8 The patient is infected by the chikungunya virus.```\n",
    "                  Error: yes\n",
    "                  Error Sentence ID: 8\n",
    "                  Error Sentence Span: The patient is infected by the chikungunya virus.\n",
    "                  Corrected Sentence: The patient is infected by the Dengue virus.\n",
    "                \n",
    "                  Example 7:\n",
    "                  Clinical Text: ```A previously healthy 25-year-old man comes to the physician with suspected Dengue viral infection because of a 4-day history of fever, joint and body pain, diffuse headache, and pain behind the eyes. This morning he noticed that his gums bled when he brushed his teeth. He returned from a backpacking trip to the Philippines 4 days ago. His temperature is 39.4 C (103.0 F). Physical examination shows a diffuse maculopapular rash. His leukocyte count is 3,200/mm3 and platelet count is 89,000/mm3. Further evaluation shows increased serum levels of a flavivirus.```\n",
    "                  Clinical Text Sentences: ```0 A previously healthy 25-year-old man comes to the physician with suspected Dengue viral infection because of a 4-day history of fever, joint and body pain, diffuse headache, and pain behind the eyes.\n",
    "                  1 This morning he noticed that his gums bled when he brushed his teeth.\n",
    "                  2 He returned from a backpacking trip to the Philippines 4 days ago.\n",
    "                  3 His temperature is 39.4 C (103.0 F).\n",
    "                  4 Physical examination shows a diffuse maculopapular rash.\n",
    "                  5 His leukocyte count is\n",
    "                  6 3,200/mm3 and platelet count is 89,000/mm3.\n",
    "                  7 Further evaluation shows increased serum levels of a flavivirus.```\n",
    "                  Error: No\n",
    "                  Error Sentence ID: -1\n",
    "                  Error Sentence Span: -1\n",
    "                  Corrected Sentence: -1\n",
    "                \n",
    "                  Now, given a new clinical text delimited by triple quotes, carefully evaluate and analyse the clinical information presented such as symptoms, clinical examination findings, patient history and other details. Determine if there is a diagnostic error or not based on this information. If an error is present, identify the specific sentence ID (and the sentence with that ID) that contains this error and also correct this erroneous sentence based on the rest of clinical text. Use your knowledge and the context provided to make your assessment.\n",
    "\n",
    "                  Clinical Text: ```{text}```\n",
    "                  Clinical Text Sentences: ```{clinical_sentences}```\n",
    "                \n",
    "                  Provide the answers in JSON Format with the following keys:\n",
    "                  Error, Error Sentence ID, Error Sentence, Corrected Sentence\n",
    "                  \"\"\"\n",
    "                  }]\n",
    "\n",
    "            completion = openai.ChatCompletion.create(engine=<engine name>,messages = message_text,\n",
    "                          temperature=0, max_tokens=800,\n",
    "                          top_p=0.95, frequency_penalty=0,\n",
    "                          presence_penalty=0, stop=None)\n",
    "            \n",
    "            message_content = completion[\"choices\"][0][\"message\"][\"content\"].strip('```json\\n').strip('\\n```')\n",
    "            message_content_json = json.loads(message_content)\n",
    "            # print(message_content_json)\n",
    "            df_val_ms.at[i, 'gpt_4_1106_preview_error_flag'] = message_content_json['Error']\n",
    "            df_val_ms.at[i, 'gpt_4_1106_preview_sentence_id'] = message_content_json['Error Sentence ID']\n",
    "            df_val_ms.at[i, 'gpt_4_1106_preview_Error_Sentence'] = message_content_json['Error Sentence']\n",
    "            df_val_ms.at[i, 'gpt_4_1106_preview_Corrected_Sentence'] = message_content_json['Corrected Sentence']\n",
    "            df_val_ms.to_csv('case_1_validMS_gpt_4_predictions_temp_file.csv',index=False)\n",
    "            break\n",
    "\n",
    "        except openai.error.APIConnectionError as e:\n",
    "            print(f\"Timeout error encountered at index {i}, attempt {retry_count + 1}: {e}\", flush=True)\n",
    "            retry_count += 1\n",
    "            time.sleep(default_wait_time)  # Wait before retrying\n",
    "\n",
    "        except openai.error.InvalidRequestError as e:\n",
    "            print(f\"InvalidRequestError at index {i}: {e}\", flush=True)\n",
    "            break\n",
    "\n",
    "        except openai.error.RateLimitError as e:\n",
    "            match = re.search(r\"Please retry after (\\d+) seconds\", str(e))\n",
    "            if match:\n",
    "                wait_time = int(match.group(1)) + 1  # Add a 1-second buffer\n",
    "            else:\n",
    "                wait_time = default_wait_time\n",
    "            print(f\"RateLimitError at index {i}. Retrying after {wait_time} seconds.\", flush=True)\n",
    "            time.sleep(wait_time)\n",
    "            retry_count += 1\n",
    "\n",
    "        except openai.error.OpenAIError as e:\n",
    "            print(f\"Unexpected OpenAIError encountered at index {i}: {e}\", flush=True)\n",
    "            break \n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error encountered at index {i}: {e}\", flush=True)\n",
    "            break\n",
    "\n",
    "df_val_ms.to_csv('case_1_validMS_gpt_4_predictions_26_03_2024.csv',index=False)\n",
    "print(\"Final csv saved!!\",flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed35eaad-56e8-4918-b21f-6c52bf592eb6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Types of error i saw:\n",
    "\n",
    "1. Timeout: Request timed out: HTTPSConnectionPool(host='sweden-api.openai.azure.com', port=443): Read timed out. (read timeout=600)\n",
    "\n",
    "2. InvalidRequestError: The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\n",
    "\n",
    "3. Request timed out: HTTPSConnectionPool(host='sweden-api.openai.azure.com', port=443): Read timed out. (read timeout=600)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fa0f00-a724-41f2-9cfd-50a733978fce",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Evaluation Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "539afe4e-025d-4c66-aaf2-2b6a16f7f068",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The submission format should follow the data format and consists of:\n",
    "\n",
    "[Text ID] [Error Flag] [Error sentence ID or -1 for texts without errors] [Corrected sentence or NA for texts without errors]\n",
    "'''\n",
    "import csv\n",
    "\n",
    "def csv_to_txt(input_csv, output_txt):\n",
    "    with open(input_csv, mode='r', encoding='utf-8') as infile, open(output_txt, mode='w', encoding='utf-8') as outfile:\n",
    "        reader = csv.DictReader(infile)\n",
    "        for row in reader:\n",
    "            text_id = row['Text ID']\n",
    "            error_flag = '1' if row['GPT_4_error_flag'].strip().lower() == 'yes' else '0'\n",
    "            sentence_id = row['GPT_4_sentence_id']\n",
    "            corrected_sentence = row['GPT_4_Corrected_Sentence']\n",
    "            if corrected_sentence == \"-1\":\n",
    "                corrected_sentence = \"NA\"\n",
    "            else:\n",
    "                corrected_sentence = f\"\\\"{corrected_sentence}\\\"\"\n",
    "            \n",
    "            line = f\"{text_id} {error_flag} {sentence_id} {corrected_sentence}\\n\"\n",
    "            outfile.write(line)\n",
    "\n",
    "# Usage\n",
    "csv_file = 'case_1.csv'  # Replace with your CSV file path\n",
    "txt_file = 'case_1.txt'  # The output TXT file path\n",
    "csv_to_txt(csv_file, txt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "7e650eb1-ac3a-43fe-b916-bb7af32ac4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def csv_to_txt(input_csv, output_txt):\n",
    "    with open(input_csv, mode='r', encoding='utf-8') as infile, open(output_txt, mode='w', encoding='utf-8') as outfile:\n",
    "        reader = csv.DictReader(infile)\n",
    "        for row in reader:\n",
    "            text_id = row['Text ID']\n",
    "            # Convert the flags to a uniform format (numerical) for comparison\n",
    "            original_error_flag = row['Error Flag'].strip()\n",
    "            gpt_error_flag = '1' if row['GPT_4_error_flag'].strip().lower() == 'yes' else '0'\n",
    "\n",
    "            # Proceed only if the error flags match\n",
    "            if original_error_flag == gpt_error_flag:\n",
    "                sentence_id = row['GPT_4_sentence_id']\n",
    "                corrected_sentence = row['GPT_4_Corrected_Sentence']\n",
    "                if corrected_sentence == \"-1\":\n",
    "                    corrected_sentence = \"NA\"\n",
    "                else:\n",
    "                    corrected_sentence = f\"\\\"{corrected_sentence}\\\"\"\n",
    "\n",
    "                # Formatting the line to be written in the text file\n",
    "                line = f\"{text_id} {gpt_error_flag} {sentence_id} {corrected_sentence}\\n\"\n",
    "                outfile.write(line)\n",
    "\n",
    "# Usage\n",
    "csv_file = 'case_1.csv'  # Replace with your CSV file path\n",
    "txt_file = 'case_1_GPT_accurate_cases.txt'  # The output TXT file path\n",
    "csv_to_txt(csv_file, txt_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "9d8e0520-7b95-4959-b422-ac3416463ace",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting rouge\n",
      "  Downloading rouge-1.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: six in /opt/modules/Python/3.11.5/lib/python3.11/site-packages (from rouge) (1.16.0)\n",
      "Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: rouge\n",
      "\u001b[33m  WARNING: The script rouge is installed in '/home/srajwal/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed rouge-1.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "b5804871-e74d-4d4f-8762-a10bd4067e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from rouge import Rouge\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "import math\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "640e0cbe-2986-4ffc-aa1d-20c535112268",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "# Parsing Funcs #\n",
    "#################\n",
    "\n",
    "\n",
    "def parse_reference_file(filepath):\n",
    "    \"\"\"Parsing reference file path.\n",
    "\n",
    "    Returns:\n",
    "        reference_corrections (dict) {text_id: \"reference correction\"}\n",
    "        reference_flags (dict) {text_id: \"1 or 0 error flag\"}\n",
    "        reference_sent_id (dict) {text_id: \"error sentence id or -1\"}\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    reference_corrections = {}\n",
    "    reference_flags = {}\n",
    "    reference_sent_id = {}\n",
    "\n",
    "    df = pd.read_csv(filepath)\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        text_id = row['Text ID']\n",
    "        corrected_sentence = row['Corrected Sentence']\n",
    "        \n",
    "        if not isinstance(corrected_sentence, str):\n",
    "            if math.isnan(corrected_sentence):\n",
    "                corrected_sentence = \"NA\"\n",
    "            else:\n",
    "                corrected_sentence = str(corrected_sentence)\n",
    "                corrected_sentence = corrected_sentence.replace(\"\\n\", \" \") \\\n",
    "                  .replace(\"\\r\", \" \").strip()\n",
    "                  \n",
    "        reference_corrections[text_id] = corrected_sentence\n",
    "        reference_flags[text_id] = str(row['Error Flag'])\n",
    "        reference_sent_id[text_id] = str(row['Error Sentence ID'])\n",
    "\n",
    "    return reference_corrections, reference_flags, reference_sent_id\n",
    "\n",
    "\n",
    "def parse_run_submission_file(filepath):\n",
    "    \n",
    "    file = open(filepath, 'r')\n",
    "\n",
    "    candidate_corrections = {}\n",
    "    predicted_flags = {}\n",
    "    candidate_sent_id = {}\n",
    "    \n",
    "    lines = file.readlines()\n",
    "    \n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        \n",
    "        if len(line) == 0:\n",
    "            continue\n",
    "            \n",
    "        if not re.fullmatch('[a-z0-9\\-]+\\s[0-9]+\\s\\-?[0-9]+\\s.+', line):\n",
    "            print(\"Invalid line: \", line)\n",
    "            continue\n",
    "            \n",
    "        # replacing consecutive spaces\n",
    "        line = re.sub('\\s+', line, ' ')\n",
    "        \n",
    "        # parsing\n",
    "        items = line.split()\n",
    "        text_id = items[0]\n",
    "        error_flag = items[1]\n",
    "        sentence_id = items[2]\n",
    "        corrected_sentence = ' '.join(items[3:]).strip()\n",
    "        \n",
    "        # debug - parsing check\n",
    "        # print(\"{} -- {} -- {} -- {}\".format(text_id, error_flag, sentence_id, corrected_sentence))\n",
    "\n",
    "        predicted_flags[text_id] = error_flag\n",
    "        candidate_sent_id[text_id] = sentence_id\n",
    "\n",
    "        # processing candidate corrections\n",
    "        # removing quotes\n",
    "\n",
    "        while corrected_sentence.startswith('\"') and len(corrected_sentence) > 1:\n",
    "            corrected_sentence = corrected_sentence[1:]\n",
    "            \n",
    "        while corrected_sentence.endswith('\"') and len(corrected_sentence) > 1:\n",
    "            corrected_sentence = corrected_sentence[:-1]\n",
    "                   \n",
    "        if error_flag == '0':\n",
    "            # enforcing \"NA\" in predicted non-errors (used for consistent/reliable eval)\n",
    "            candidate_corrections[text_id] = \"NA\"\n",
    "        else:\n",
    "            candidate_corrections[text_id] = corrected_sentence\n",
    "\n",
    "    return candidate_corrections, predicted_flags, candidate_sent_id\n",
    "\n",
    "\n",
    "##############\n",
    "# Eval Funcs #\n",
    "##############\n",
    "\n",
    "def compute_accuracy(reference_flags, reference_sent_id, predicted_flags, candidate_sent_id):\n",
    "    # Error Flags Accuracy (missing predictions are counted as false)\n",
    "    matching_flags_nb = 0\n",
    "    \n",
    "    for text_id in reference_flags:\n",
    "        if text_id in predicted_flags and reference_flags[text_id] == predicted_flags[text_id]:\n",
    "            matching_flags_nb += 1\n",
    "            \n",
    "    flags_accuracy = matching_flags_nb / len(reference_flags)\n",
    "    \n",
    "    # Error Sentence Detection Accuracy (missing predictions are counted as false)\n",
    "    matching_sentence_nb = 0\n",
    "    \n",
    "    for text_id in reference_sent_id:\n",
    "        if text_id in candidate_sent_id and candidate_sent_id[text_id] == reference_sent_id[text_id]:\n",
    "            matching_sentence_nb += 1\n",
    "            \n",
    "    sent_accuracy = matching_sentence_nb / len(reference_sent_id)\n",
    "\n",
    "    return {\n",
    "        \"Error Flags Accuracy\": flags_accuracy,\n",
    "        \"Error Sentence Detection Accuracy\": sent_accuracy\n",
    "    }\n",
    "\n",
    "def increment_counter(counters, counter_name):\n",
    "    counters[counter_name] = counters[counter_name] + 1\n",
    "\n",
    "class NLGMetrics(object):\n",
    "\n",
    "    def __init__(self, metrics = ['ROUGE']):\n",
    "        self.metrics = metrics\n",
    "    \n",
    "    def compute(self, references, predictions, counters):\n",
    "        results = {}\n",
    "        \n",
    "        if 'ROUGE' in self.metrics:\n",
    "            rouge = Rouge() \n",
    "            rouge_scores = rouge.get_scores(predictions, references)\n",
    "                            \n",
    "            rouge1f_scores = []\n",
    "            rouge2f_scores = []\n",
    "            rougeLf_scores = []\n",
    "            \n",
    "            for i in range(len(references)):\n",
    "                r1f = rouge_scores[i][\"rouge-1\"][\"f\"]\n",
    "                r2f = rouge_scores[i][\"rouge-2\"][\"f\"]\n",
    "                rlf = rouge_scores[i][\"rouge-l\"][\"f\"]\n",
    "                \n",
    "                rouge1f_scores.append(r1f)\t\n",
    "                rouge2f_scores.append(r2f)\n",
    "                rougeLf_scores.append(rlf)\n",
    "                \n",
    "            # for checking comparison with composite\n",
    "            rouge1check = np.array(rouge1f_scores).mean()\n",
    "            rouge2check = np.array(rouge2f_scores).mean()\n",
    "            rougeLcheck = np.array(rougeLf_scores).mean()\n",
    "\n",
    "            results['R1F_subset_check'] = rouge1check\n",
    "            results['R2F_subset_check'] = rouge2check\n",
    "            results['RLF_subset_check'] = rougeLcheck\n",
    "            \n",
    "            ###############################\n",
    "            # Composite score computation #\n",
    "            ###############################\n",
    "            \n",
    "            \"\"\"\n",
    "            NLG METRIC on sentence vs. sentence cases + ones or zeros \n",
    "            when either the reference or the candidate correction is NA\n",
    "            \"\"\"\n",
    "            \n",
    "            rouge1score = np.array(rouge1f_scores).sum()\n",
    "            rouge2score = np.array(rouge2f_scores).sum()\n",
    "            rougeLscore = np.array(rougeLf_scores).sum()\n",
    "            \n",
    "            composite_score_rouge1 = (rouge1score + counters[\"system_provided_correct_na\"]) / counters[\"total_texts\"]\n",
    "            composite_score_rouge2 = (rouge2score + counters[\"system_provided_correct_na\"]) / counters[\"total_texts\"]\n",
    "            composite_score_rougeL = (rougeLscore + counters[\"system_provided_correct_na\"]) / counters[\"total_texts\"]\n",
    "\n",
    "            results['R1FC'] = composite_score_rouge1\n",
    "            results['R2FC'] = composite_score_rouge2\n",
    "            results['RLFC'] = composite_score_rougeL\n",
    "\n",
    "        \n",
    "        return results\n",
    "\n",
    "\n",
    "def get_nlg_eval_data(reference_corrections, candidate_corrections, remove_nonprint = False):\n",
    "    references = []\n",
    "    predictions = []\n",
    "    \n",
    "    counters = {\n",
    "        \"total_texts\": 0,\n",
    "        \"reference_na\": 0,\n",
    "        \"total_system_texts\": 0,\n",
    "        \"system_provided_na\": 0,\n",
    "        \"system_provided_correct_na\": 0,\n",
    "    }\n",
    "    \n",
    "    for text_id in reference_corrections:\n",
    "        increment_counter(counters, \"total_texts\")\n",
    "        \n",
    "        # removing non ascii chars\n",
    "        reference_correction = reference_corrections[text_id]\n",
    "        \n",
    "        if remove_nonprint:\n",
    "            reference_correction = ''.join(filter(lambda x: x in string.printable, str(reference_correction)))\n",
    "            \n",
    "        if reference_correction == \"NA\":\n",
    "            increment_counter(counters, \"reference_na\")\n",
    "            \n",
    "        if text_id in candidate_corrections:\n",
    "            increment_counter(counters, \"total_system_texts\")\n",
    "            candidate = candidate_corrections[text_id]\n",
    "            \n",
    "            if remove_nonprint:\n",
    "                candidate = ''.join(filter(lambda x: x in string.printable, candidate))\n",
    "                \n",
    "            if candidate == \"NA\":\n",
    "                increment_counter(counters, \"system_provided_na\")\n",
    "                \n",
    "            # matching NA counts as 1\n",
    "            if reference_correction == \"NA\" and candidate == \"NA\":\n",
    "                increment_counter(counters, \"system_provided_correct_na\")\n",
    "                continue\n",
    "                \n",
    "            # Run provided \"NA\" when a correction was required (=> 0)\n",
    "            # or Run provided a correction when \"NA\" was required (=> 0)\n",
    "            if candidate == \"NA\" or reference_correction == \"NA\":\n",
    "                continue\n",
    "                \n",
    "            # remaining case is both reference and candidate are not \"NA\"\n",
    "            # both are inserted/added for ROUGE/BLEURT/etc. computation\n",
    "            references.append(reference_correction)\n",
    "            predictions.append(candidate)\n",
    "    \n",
    "\n",
    "    \n",
    "    return references, predictions, counters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "c5290db4-af0f-46bc-8dc7-5c546064c9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid line:  ms-train-426 0  \"nan\"\n",
      "Invalid line:  ms-train-637 0  \"nan\"\n",
      "Invalid line:  ms-train-750 0  \"nan\"\n",
      "Invalid line:  ms-train-937 0  \"nan\"\n",
      "Invalid line:  ms-train-938 0  \"nan\"\n",
      "Invalid line:  ms-train-968 0  \"nan\"\n",
      "Invalid line:  ms-train-969 0  \"nan\"\n",
      "Invalid line:  ms-train-1003 0  \"nan\"\n",
      "Invalid line:  ms-train-1108 0  \"nan\"\n",
      "Invalid line:  ms-train-1276 0  \"nan\"\n",
      "Accuracy Results:\n",
      " {'Error Flags Accuracy': 0.6359068067610781, 'Error Sentence Detection Accuracy': 0.6222019186843307}\n",
      "\n",
      "NLG Eval Results:\n",
      " {'R1F_subset_check': 0.5894396772329137, 'R2F_subset_check': 0.4736292629615664, 'RLF_subset_check': 0.5842031368423116, 'R1FC': 0.433533765068211, 'R2FC': 0.37644859512815443, 'RLFC': 0.430952574076224}\n",
      "\n",
      "{'total_texts': 2189, 'reference_na': 970, 'total_system_texts': 2179, 'system_provided_na': 447, 'system_provided_correct_na': 313}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "submission_file = \"case_1.txt\"\n",
    "reference_csv_file = \"MEDIQA-CORR-2024-MS-TrainingData.csv\"\n",
    "\n",
    "reference_corrections, reference_flags, reference_sent_id = parse_reference_file(reference_csv_file)\n",
    "candidate_corrections, candidate_flags, candidate_sent_id = parse_run_submission_file(submission_file)\n",
    "\n",
    "# Accuracy\n",
    "accuracy_results = compute_accuracy(reference_flags, reference_sent_id, candidate_flags, candidate_sent_id)\n",
    "print(\"Accuracy Results:\\n\", accuracy_results)\n",
    "print()\n",
    "\n",
    "# NLG Eval for corrections\n",
    "references, predictions, counters = get_nlg_eval_data(reference_corrections, candidate_corrections)\n",
    "metrics = NLGMetrics()\n",
    "nlg_eval_results = metrics.compute(references, predictions, counters) \n",
    "\n",
    "print(\"NLG Eval Results:\\n\", nlg_eval_results) \n",
    "print()\n",
    "\n",
    "# debug check\n",
    "print(counters)\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
